{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# read the csv files\n",
    "df = pd.read_csv('../data/rodpump_failure_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the columns to make them more intuitive and easier to use\n",
    "df.rename(columns={'roduid':'rod_uid',\n",
    "                       'UWI':'uwi',\n",
    "                       'NODEID':'well_name',\n",
    "                       'IDWELL':'well_id',\n",
    "                       'tbguid':'bha_tubing_id',\n",
    "                       'lifetime_start':'bha_lifetime_start',\n",
    "                       'lifetime_end' :'bha_lifetime_end',\n",
    "                       'IDRECJOBPULL' : 'bha_lifetime_id',\n",
    "                       'REPORTTO' : 'failure_type',\n",
    "                       'H2S_CONCENTRATION' : 'h2s_conc',\n",
    "                       'PrimarySetpoint' : 'primary_setpoint',\n",
    "                       'SecondarySetpoint' : 'secondary_setpoint',\n",
    "                       'StrokeLength' : 'stroke_len',\n",
    "                       'GrossStrokeLength' : 'gross_stroke_len',\n",
    "                       'Fillage' : 'fillage',\n",
    "                       'YesterdaysAverageSPM' : 'yesterday_avg_spm',\n",
    "                       'bha_configuration' : 'bha_config',\n",
    "                       'gas_anchor_length' : 'gas_anchor_len',\n",
    "                       'MAX_INCLINATION' : 'max_incline',\n",
    "                       'AVG_PRESS_FLOWLINE' : 'avg_press_flowline',\n",
    "                       'AVG_PRESSURE_TUBING' : 'avg_press_tubing',\n",
    "                       'AVG_PRESSURE_CASING' : 'avg_press_casing',\n",
    "                       'AVG_DIFFERENTIAL_PRESSURE' : 'avg_diff_press',\n",
    "                       'AVG_OIL_VOLUME' : 'avg_oil_vol',\n",
    "                       'AVG_WATER_VOLUME' : 'avg_water_vol',\n",
    "                       'AVG_LIQUID_VOLUME' : 'avg_liquid_vol',\n",
    "                       'AVG_WATERSG' : 'avg_watersg',\n",
    "                       'ROUTE' : 'route',\n",
    "                       'DESANDDEGAS_TYP' : 'dsand_dgas_type',\n",
    "                       'CHROME_LENGTH' : 'chrome_len',\n",
    "                       'ENDURALLOY_LENGTH' : 'enduralloy_len',\n",
    "                       'POLY_LENGTH' : 'poly_len',\n",
    "                       'NIPPLE_SET_DEPTH' : 'nip_set_depth',\n",
    "                       'gasanchor_od' : 'gas_anchor_od'}, inplace = True)\n",
    "# drop unnecessary columns\n",
    "df.drop(columns = ['FAILSTART', 'FAILURETYPE'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['manual_scale'] = df['manual_scale'].map({'Y': True, 'N': False})\n",
    "for col in df.columns:\n",
    "    if len(df[col].unique()) == 2:\n",
    "        df[col] = df[col].astype(bool)\n",
    "\n",
    "# convert date columns to datetime and create a new column 'bha_lifetime'\n",
    "date_cols = ['bha_lifetime_start', 'bha_lifetime_end']\n",
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "df['bha_lifetime'] = (df['bha_lifetime_end'] - df['bha_lifetime_start']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling null values\n",
    "\n",
    "# for numeric columns, fill missing values with the median\n",
    "# use the median because the data is heavily skewed\n",
    "for col in df.select_dtypes(include = 'number').columns:\n",
    "    median_val = df[col].median()\n",
    "    df[col] = df[col].fillna(median_val)\n",
    "\n",
    "# for categorical columns, fill missing values with the mode (or \"Unknown\" if mode is not available)\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    if col not in [\"failure_type\", \"rod_uid\", \"well_name\",\n",
    "                   \"well_id\", \"bha_tubing_id\", \"bha_lifetime_start\",\n",
    "                   \"bha_lifetime_end\", \"bha_lifetime_id\"]:  # Exclude failure_type and id columns\n",
    "        if not df[col].mode().empty:\n",
    "            mode_val = df[col].mode()[0]\n",
    "        else:\n",
    "            mode_val = \"Unknown\"\n",
    "        df[col] = df[col].fillna(mode_val)\n",
    "    elif col == \"failure_type\":\n",
    "        df.loc[df[\"bha_lifetime_end\"] == \"2020-04-15 17:37:11.338\", col] = df[col].fillna(\"No fail\")\n",
    "        df.loc[df[\"bha_lifetime_end\"] != \"2020-04-15 17:37:11.338\", col] = df[col].fillna(df[col].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (2596, 54)\n",
      "Removed outliers in fillage: 102 rows dropped\n",
      "Removed outliers in max_unguided_dls: 81 rows dropped\n",
      "Removed outliers in dls_high_in_hole: 5 rows dropped\n",
      "Removed outliers in max_incline: 57 rows dropped\n",
      "Removed outliers in avg_press_tubing: 54 rows dropped\n",
      "Removed outliers in avg_press_casing: 43 rows dropped\n",
      "Removed outliers in avg_diff_press: 35 rows dropped\n",
      "Removed outliers in avg_oil_vol: 7 rows dropped\n",
      "Removed outliers in avg_water_vol: 39 rows dropped\n",
      "Removed outliers in avg_liquid_vol: 1 rows dropped\n",
      "Removed outliers in overall_max_sideload: 83 rows dropped\n",
      "Removed outliers in shallow_max_sideload: 8 rows dropped\n",
      "Removed outliers in max_unguided_sideload: 50 rows dropped\n",
      "Removed outliers in chrome_len: 20 rows dropped\n",
      "Removed outliers in poly_len: 25 rows dropped\n",
      "Removed outliers in nip_set_depth: 9 rows dropped\n",
      "Capped outliers in yesterday_avg_spm at 1st and 99th percentiles\n",
      "Capped outliers in gas_anchor_len at 1st and 99th percentiles\n",
      "Capped outliers in stroke_len at 15th and 85th percentiles\n",
      "Capped outliers in gross_stroke_len at 10th and 90th percentiles\n",
      "Capped outliers in avg_press_flowline at 10th and 90th percentiles\n",
      "Final shape after selective outlier removal: (1977, 54)\n"
     ]
    }
   ],
   "source": [
    "# outlier detection and removal (selective)\n",
    "\n",
    "# Define the helper function to remove outliers using the IQR method.\n",
    "def remove_outliers_iqr(data, col, multiplier=5.0):\n",
    "    q1 = data[col].quantile(0.25)\n",
    "    q3 = data[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - multiplier * iqr\n",
    "    upper_bound = q3 + multiplier * iqr\n",
    "    return data[(data[col] >= lower_bound) & (data[col] <= upper_bound)]\n",
    "\n",
    "# Define the list of columns for which we want to remove outliers.\n",
    "# We are skipping 'stroke_len', 'yesterday_avg_spm', 'avg_press_flowline', and 'gas_anchor_len'\n",
    "# because they appear to have valid variation even if their statistical spread is high.\n",
    "\n",
    "cols_to_clean = [\n",
    "    'fillage',\n",
    "    'max_unguided_dls',\n",
    "    'dls_high_in_hole',\n",
    "    'max_incline',\n",
    "    'avg_press_tubing',\n",
    "    'avg_press_casing',\n",
    "    'avg_diff_press',\n",
    "    'avg_oil_vol',\n",
    "    'avg_water_vol',\n",
    "    'avg_liquid_vol',\n",
    "    'overall_max_sideload',\n",
    "    'shallow_max_sideload',\n",
    "    'max_unguided_sideload',\n",
    "    'chrome_len',\n",
    "    'poly_len',\n",
    "    'nip_set_depth'\n",
    "]\n",
    "\n",
    "# Track the initial row count.\n",
    "print(\"Initial shape:\", df.shape)\n",
    "\n",
    "# Apply outlier removal only for columns in cols_to_clean.\n",
    "for col in cols_to_clean:\n",
    "    if col in df.columns:\n",
    "        before_shape = df.shape\n",
    "        df = remove_outliers_iqr(df, col, multiplier=3.0)\n",
    "        after_shape = df.shape\n",
    "        print(f\"Removed outliers in {col}: {before_shape[0] - after_shape[0]} rows dropped\")\n",
    "\n",
    "# Apply percentile-based capping for 'stroke_len', 'yesterday_avg_spm', 'avg_press_flowline', and 'gas_anchor_len'\n",
    "special_cols = ['yesterday_avg_spm', 'gas_anchor_len']\n",
    "for col in special_cols:\n",
    "    lower_limit = df[col].quantile(0.01)\n",
    "    upper_limit = df[col].quantile(0.99)\n",
    "    df[col] = df[col].clip(lower=lower_limit, upper=upper_limit)\n",
    "    print(f\"Capped outliers in {col} at 1st and 99th percentiles\")\n",
    "\n",
    "# Adjust outliers for stroke_len and gross_stroke_len by capping at 99th percentile\n",
    "for col in ['stroke_len']:\n",
    "    lower_limit = df[col].quantile(0.20)\n",
    "    upper_limit = df[col].quantile(0.80)\n",
    "    df[col] = df[col].clip(lower=lower_limit, upper=upper_limit)\n",
    "    print(f\"Capped outliers in {col} at 15th and 85th percentiles\")\n",
    "\n",
    "# Adjust outliers for stroke_len and gross_stroke_len by capping at 99th percentile\n",
    "for col in ['gross_stroke_len','avg_press_flowline']:\n",
    "    lower_limit = df[col].quantile(0.10)\n",
    "    upper_limit = df[col].quantile(0.90)\n",
    "    df[col] = df[col].clip(lower=lower_limit, upper=upper_limit)\n",
    "    print(f\"Capped outliers in {col} at 10th and 90th percentiles\")\n",
    "\n",
    "print(\"Final shape after selective outlier removal:\", df.shape) # basically lost 24%ish outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['failure_type'] != 'Liner (Casing)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data cleaning complete. Cleaned data saved as \"rod_cleaned_final.csv\".\n"
     ]
    }
   ],
   "source": [
    "# Save the Final Cleaned Data\n",
    "df.to_csv('../data/rod_cleaned_no_transform.csv', index=False)\n",
    "print('\\nData cleaning complete. Cleaned data saved as \"rod_cleaned_final.csv\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
